{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in the price_quality komen nu infs, vervangen door nan?\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe you want to clean, can be a csv, hdf\n",
    "# traindf = pd.read_csv(\"./data/training_set_VU_DM.csv\")\n",
    "traindf = pd.read_csv(\"./data/test_set_VU_DM.csv\")\n",
    "\n",
    "# put filename here: we use hdf because it can store the entire dataset, while pickle files can't\n",
    "# filename = \"./data/traindf_clean.hdf\"\n",
    "filename = \"./data/test_clean.hdf\"\n",
    "\n",
    "# if testing set is True we will not add the importance column (because we can't)\n",
    "testing_set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(df):\n",
    "    \"\"\"\n",
    "    Balance classes in trainingset, based on click_bool (not booking_bool)\n",
    "    \"\"\"\n",
    "    # Get 50% of data with importance of 5 or 1\n",
    "    clicks = df[df.importance != 0].index\n",
    "    randoms = np.random.choice(clicks, len(df.loc[df.importance != 0]) , replace=False)\n",
    "    click_sample = df.loc[randoms]\n",
    "    \n",
    "    # Other 50% of the data\n",
    "    not_click = df[df.importance == 0].index\n",
    "    random_indices = np.random.choice(not_click, len(df.loc[df.importance == 0]), replace=False)\n",
    "    not_click_sample = df.loc[random_indices]\n",
    "\n",
    "    df_new = pd.concat([not_click_sample, click_sample], axis=0)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitors(df):\n",
    "    \"\"\"\n",
    "    Make a new column in the dataframe (competitor_bool) for when there \n",
    "    exists a competitor and there are available rooms.\n",
    "    1 is True, 0 is False.\n",
    "    \"\"\"\n",
    "\n",
    "    # we say that there is no competitor with a lower price\n",
    "    df[\"competitor_lower\"] = 0 #competitor_bools\n",
    "    \n",
    "    # comp1rate = 1 if price is lower\n",
    "    df[\"competitor_lower\"][df[\"comp1_rate\"] == 1] = 1\n",
    "    df[\"competitor_lower\"][df[\"comp2_rate\"] == 1] = 1\n",
    "    df[\"competitor_lower\"][df[\"comp3_rate\"] == 1] = 1\n",
    "    df[\"competitor_lower\"][df[\"comp4_rate\"] == 1] = 1\n",
    "    df[\"competitor_lower\"][df[\"comp5_rate\"] == 1] = 1\n",
    "    df[\"competitor_lower\"][df[\"comp6_rate\"] == 1] = 1\n",
    "    df[\"competitor_lower\"][df[\"comp7_rate\"] == 1] = 1\n",
    "    df[\"competitor_lower\"][df[\"comp8_rate\"] == 1] = 1\n",
    "    \n",
    "    # we say at first there is no competitor hotel available\n",
    "    df[\"competitor_available\"] = 0\n",
    "    \n",
    "    # availability bool = 1 if there if the competitor and expedia are available\n",
    "    df[\"competitor_available\"][df[\"comp1_inv\"] == 1] = 1\n",
    "    df[\"competitor_available\"][df[\"comp2_inv\"] == 1] = 1\n",
    "    df[\"competitor_available\"][df[\"comp3_inv\"] == 1] = 1\n",
    "    df[\"competitor_available\"][df[\"comp4_inv\"] == 1] = 1\n",
    "    df[\"competitor_available\"][df[\"comp5_inv\"] == 1] = 1\n",
    "    df[\"competitor_available\"][df[\"comp6_inv\"] == 1] = 1\n",
    "    df[\"competitor_available\"][df[\"comp7_inv\"] == 1] = 1\n",
    "    df[\"competitor_available\"][df[\"comp8_inv\"] == 1] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visitor_history(df):\n",
    "    \"\"\"\n",
    "    Add column that tells us whether someone has visited a hotel before.\n",
    "    Column name = total_visited; 1 is True, 0 is False.\n",
    "    \"\"\"\n",
    "    \n",
    "    # most visitors haven't visited a hotel yet\n",
    "    df[\"visited_before\"] = 0\n",
    "    \n",
    "    # where there is a history field filled in, visited_before is turned into 21\n",
    "    df[\"visited_before\"][df[\"visitor_hist_starrating\"].notna() | df[\"visitor_hist_adr_usd\"].notna()] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_quality(df):\n",
    "    \"\"\"\n",
    "    Add a column of ratio price/quality to the DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"price_quality\"] = None\n",
    "    \n",
    "    df[\"prop_starrating\"].replace(0, 0.0001,inplace=True) # TODO\n",
    "    \n",
    "    df[\"price_quality\"][df[\"price_usd\"].notna() & df[\"prop_starrating\"].notna() & df[\"prop_starrating\"] != 0] = df[\"price_usd\"] / df[\"prop_starrating\"]\n",
    "\n",
    "    # Replace missing values with median\n",
    "    df[\"price_quality\"].fillna((df[\"price_quality\"].median()), inplace=True)\n",
    "    \n",
    "    return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_category(df):\n",
    "    \"\"\"\n",
    "    Add a column of categories of price_usd and a column\n",
    "    that corrected price for number of nights.\n",
    "    Preprocessing of quantile cut showed that categories are:\n",
    "    [(6.0889999999999995, 69.0] < (69.0, 90.0] < (90.0, 110.0] \n",
    "    < (110.0, 136.0] < (136.0, 170.077] < (170.077, 239.0] < (239.0, 554655.0]]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Correct for number of nights ad add as new column\n",
    "    df[\"price_correction\"] = df[\"price_usd\"] / df[\"srch_length_of_stay\"]\n",
    "    \n",
    "    # Replace missing values\n",
    "    df[\"price_correction\"].fillna((df[\"price_correction\"].median()), inplace=True)\n",
    "    df[\"price_usd\"].fillna((df[\"price_usd\"].median()), inplace=True)\n",
    "    \n",
    "    # Make a new column of price categories\n",
    "    # TODO: apparently this is not a number\n",
    "    df['PriceBand'] = pd.qcut(df[\"price_correction\"], 7, labels=np.arange(1,8))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_remaining_cols(df):\n",
    "    \"\"\"\n",
    "    Add some remaining (and interesting columns) to the dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace missing values with median\n",
    "    df[\"prop_brand_bool\"].fillna((df[\"prop_brand_bool\"].median()), inplace=True)\n",
    "    df[\"random_bool\"].fillna((df[\"random_bool\"].median()), inplace=True)\n",
    "    \n",
    "    # Boolians\n",
    "#     df[\"prop_location_score1\"].fillna((df[\"prop_location_score1\"].mean()), inplace=True)\n",
    "    df[\"prop_location_score1\"].fillna(0, inplace=True)\n",
    "    df[\"prop_location_score2\"].fillna(0, inplace=True)\n",
    "        \n",
    "    # Replace missing values with mean\n",
    "#     df[\"promotion_flag\"].fillna((df[\"promotion_flag\"].mean()), inplace=True)\n",
    "    df[\"promotion_flag\"].fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_score(df):\n",
    "    \"\"\"\n",
    "    Add an importance score based on click_bool and booking_bool\n",
    "    \"\"\"\n",
    "    \n",
    "    # every hotel that is clicked on gets an importance score of 1\n",
    "    df[\"importance\"] = df[\"click_bool\"]\n",
    "    \n",
    "    # every hotel that is booked gets an importance score of 5 \n",
    "    df[\"importance\"][df[\"booking_bool\"] == 1] = 5\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_id_score(df):\n",
    "    \"\"\"\n",
    "    The average price and standard deviation per prop_id\n",
    "    \"\"\" \n",
    "    \n",
    "    df[\"prop_id_price_mean\"] = df.groupby('prop_id')['price_quality'].transform('mean')\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aparte functies aanroepen voor de kolommen die je erbij wilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = competitors(traindf)\n",
    "print(\"cleaned competitors\")\n",
    "\n",
    "traindf = visitor_history(traindf)\n",
    "print(\"cleaned visitor history\")\n",
    "\n",
    "traindf = price_quality(traindf)\n",
    "print(\"cleaned price quality\")\n",
    "\n",
    "traindf = price_category(traindf)\n",
    "print(\"cleaned price category\")\n",
    "\n",
    "traindf = process_remaining_cols(traindf)\n",
    "print(\"did remaining columns\")\n",
    "\n",
    "traindf = prop_id_score(traindf)\n",
    "print(\"added prop_id_score\")\n",
    "\n",
    "# Add relevant columns    \n",
    "if testing_set is False:\n",
    "    \n",
    "    df = traindf[[\"prop_id\", \n",
    "                  \"srch_id\", \n",
    "                  \"position\", \n",
    "                  \"price_quality\", \n",
    "                  \"competitor_lower\", \n",
    "                  \"competitor_available\", \n",
    "                  \"visited_before\", \n",
    "                  \"click_bool\", \n",
    "                  \"booking_bool\", \n",
    "                  \"PriceBand\", \n",
    "                  \"price_usd\",\n",
    "                  \"promotion_flag\", \n",
    "                  \"prop_brand_bool\", \n",
    "                  \"random_bool\",\n",
    "                  \"prop_location_score1\", \n",
    "                  \"prop_location_score2\",\n",
    "                  \"prop_id_price_mean\"]]\n",
    "    \n",
    "    df = add_score(df)\n",
    "    print(\"added score\")\n",
    "    \n",
    "    # Balance data to 50% importance score or 1 or 5 and 0 \n",
    "    df = downsampling(df)\n",
    "    print(\"Downsampled data\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # df without click_bool, booking_bool and position\n",
    "    df = traindf[[\"prop_id\", \n",
    "                  \"srch_id\", \n",
    "                  \"price_quality\", \n",
    "                  \"competitor_lower\", \n",
    "                  \"competitor_available\", \n",
    "                  \"visited_before\", \n",
    "                  \"PriceBand\", \n",
    "                  \"price_usd\",\n",
    "                  \"promotion_flag\", \n",
    "                  \"prop_brand_bool\", \n",
    "                  \"random_bool\",\n",
    "                  \"prop_location_score1\", \n",
    "                  \"prop_location_score2\",\n",
    "                  \"prop_id_price_mean\"\n",
    "                 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"price_quality\"] = df.price_quality.astype(np.float32)\n",
    "print(df.dtypes)\n",
    "print()\n",
    "\n",
    "if df.isnull().sum().sum() != 0:    \n",
    "    print(\"\\x1b[31mMissing values: \\'\\x1b[0m\")\n",
    "    print(df.isnull().sum())\n",
    "else:\n",
    "    print(\"\\x1b[31mNo missing values!! :D \\'\\x1b[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Totale dataset zonder missende waardes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe if it does not exist yet\n",
    "# if not os.path.exists(filename):\n",
    "#     df.to_hdf(filename, key=\"df\", format=\"table\")\n",
    "df.to_hdf(filename, key=\"df\", format=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if it worked\n",
    "reread = pd.read_hdf(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(reread.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
