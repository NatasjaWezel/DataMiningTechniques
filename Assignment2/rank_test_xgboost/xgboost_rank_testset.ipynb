{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_hdf(\"../data/traindf_clean.hdf\")\n",
    "testdf = pd.read_hdf(\"../data/test_clean.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = [\"prop_location_score1\", \"price_correction\", \"avg_price_propid_after\", \"locationscore1_rank\", \"price_usd\", \"starrating_rank\"]\n",
    "traindf = traindf.drop(dropcols, axis=1)\n",
    "testdf =  testdf.drop(dropcols, axis=1)\n",
    "\n",
    "print(list(traindf.columns))\n",
    "print(list(testdf.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.sort_values(by=['srch_id'])\n",
    "testdf = testdf.sort_values(by=['srch_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split label and other variables\n",
    "x_train, y_train = traindf, traindf[\"importance\"]\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, \n",
    "#                                                     test_size=0.99, \n",
    "#                                                     random_state=42, \n",
    "#                                                     shuffle=False, \n",
    "#                                                     stratify = None)\n",
    "\n",
    "\n",
    "# Drop columns that are to be predicted with importance (which is set to y_train)\n",
    "x_train = x_train.drop(columns=[\"position\", \"importance\", \"booking_bool\", \"click_bool\"])\n",
    "\n",
    "# x_test is the total testset with all columns. \n",
    "x_test = testdf\n",
    "\n",
    "x_test = x_test.reindex(x_train.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for correct shape and columns;\n",
    "# x_train is probably much smaller because of downsampling: (50% of importance 5 and 1, 50% importance 0). \n",
    "# Number of columns in x_train and x_test must be equal!\n",
    "print(x_train.shape, y_train.shape, x_test.shape)\n",
    "print(list(x_train.columns))\n",
    "print(list(x_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'rank:ndcg', 'learning_rate': 0.11,\n",
    "          'max_depth': 6,  'n_estimators': 1000}\n",
    "\n",
    "# groups are equal to length of unique queries\n",
    "query_lengths = x_train.groupby('srch_id').size().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.sklearn.XGBRanker(**params)\n",
    "model.fit(x_train.drop([\"prop_id\", \"srch_id\", 'better_available_competitor', 'visited_before', 'prop_starrating', 'prop_review_score', 'std_avg_price_propid_after', 'prop_location_score1', 'price_correction'], axis=1), y_train, query_lengths, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make fake column of positions to test score in ndcg scoring function,\n",
    "# This is not needed for the testset, because there is nothing to check in the testset\n",
    "# x_train[\"position_temp\"] = x_train.groupby(['srch_id']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[\"position\"] = y_train\n",
    "predictions_sorted = []\n",
    "prop_ids_sorted = []\n",
    "\n",
    "# Sort predictions for each group SEPERATELY\n",
    "for srchid, group in x_test.groupby('srch_id'):\n",
    "\n",
    "    # Predictions for one search_id\n",
    "    pred = model.predict(group.drop([\"prop_id\", \"srch_id\",'better_available_competitor', 'visited_before', 'prop_starrating', 'prop_review_score', 'std_avg_price_propid_after', 'prop_location_score1', 'price_correction'], axis=1))\n",
    "\n",
    "    \n",
    "    prop_id = [x for _,x in sorted(zip(pred, group.prop_id), reverse=True)]\n",
    "    prop_ids_sorted.append(prop_id)\n",
    "    \n",
    "# Flatten lists\n",
    "predictions_sorted = [item for sublist in predictions_sorted for item in sublist]\n",
    "prop_ids_sorted = [item for sublist in prop_ids_sorted for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[\"prop_id\"] = prop_ids_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set only: convert to csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"submission214mei.csv\"\n",
    "final_df = x_test[[\"srch_id\", \"prop_id\"]]\n",
    "final_df.to_csv(filename, columns=[\"srch_id\", \"prop_id\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test if it worked\n",
    "test = pd.read_csv(filename)\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plot = xgb.plot_importance(booster=model)\n",
    "plot.figure.savefig(\"../plots/featureimportance18mei.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('better_available_competitor',\n",
       " 'visited_before',\n",
       " 'prop_starrating',\n",
       " 'prop_review_score',\n",
       " 'std_avg_price_propid_after',\n",
       " 'prop_location_score1',\n",
       " 'price_correction')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'better_available_competitor', 'visited_before', 'prop_starrating', 'prop_review_score', 'std_avg_price_propid_after', 'prop_location_score1', 'price_correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
